import streamlit as st
import pandas as pd
import plotly.express as px
import FinanceDataReader as fdr
import requests
import urllib3
from io import StringIO, BytesIO
from datetime import datetime, timedelta
import yfinance as yf
import feedparser
import numpy as np
import pytz

# [í•„ìˆ˜] ê°™ì€ í´ë”ì˜ etf.pyì—ì„œ í´ë˜ìŠ¤ ì„í¬íŠ¸
try:
    from etf import ActiveETFMonitor
except ImportError:
    st.error("âš ï¸ 'etf.py' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

# ë³´ì•ˆ ì¸ì¦ì„œ ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ---------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="MAS Strategy Dashboard",
    page_icon="ğŸŠ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------------------------------------------
# 2. ë°ì´í„° ìˆ˜ì§‘ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------

@st.cache_data(ttl=600)
def fetch_market_data():
    """ì‹œì¥ í•µì‹¬ ì§€í‘œ ìˆ˜ì§‘"""
    tickers = {
        "KOSPI": "^KS11", "S&P500": "^GSPC", "Nasdaq": "^IXIC", 
        "USD/KRW": "KRW=X", "US 10Y": "^TNX", "WTI Oil": "CL=F"
    }
    data_dict = {}
    history_dict = {}
    
    for name, code in tickers.items():
        try:
            obj = yf.Ticker(code)
            hist = obj.history(period="1y")
            if not hist.empty:
                current = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2]
                pct_change = ((current - prev) / prev) * 100
                hist['MA20'] = hist['Close'].rolling(window=20).mean()
                trend = "ìƒìŠ¹" if current > hist['MA20'].iloc[-1] else "í•˜ë½"
                data_dict[name] = {"price": current, "pct_change": pct_change, "trend": trend}
                history_dict[name] = hist
        except: continue
    return data_dict, history_dict

def to_excel(df_new, df_inc, df_dec, df_all, date):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_new.to_excel(writer, index=False, sheet_name='ì‹ ê·œí¸ì…')
        df_inc.to_excel(writer, index=False, sheet_name='ë¹„ì¤‘í™•ëŒ€')
        df_dec.to_excel(writer, index=False, sheet_name='ë¹„ì¤‘ì¶•ì†Œ')
        df_all.to_excel(writer, index=False, sheet_name='ì „ì²´í¬íŠ¸í´ë¦¬ì˜¤')
    return output.getvalue()



def fetch_yahoo_news(tickers):
    """Yahoo Finance ë‰´ìŠ¤ ìˆ˜ì§‘ (ë” ì‹ ë¢°ë„ ë†’ì€ ì†ŒìŠ¤)"""
    news_items = []
    try:
        # ì—¬ëŸ¬ í‹°ì»¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
        for ticker in tickers:
            stock = yf.Ticker(ticker)
            news = stock.news
            if news:
                for n in news:
                    # YF ë‰´ìŠ¤ êµ¬ì¡°: title, link, providerPublishTime, publisher
                    pub_time = n.get('providerPublishTime', 0)
                    dt = datetime.fromtimestamp(pub_time)
                    
                    news_items.append({
                        "title": n.get('title', ''),
                        "link": n.get('link', ''),
                        "published_dt": dt,
                        "published": dt.strftime("%Y-%m-%d %H:%M"),
                        "source": f"Yahoo ({n.get('publisher', 'Unknown')})"
                    })
    except Exception as e:
        # st.error(f"Yahoo News Error: {e}") # ë””ë²„ê¹…ìš©
        pass
        
    return news_items

@st.cache_data(ttl=3600)
def fetch_global_events():
    """ì „ì²´ ì‹œì¥ í•µì‹¬ ì´ë²¤íŠ¸ ìˆ˜ì§‘ (Google News + Yahoo Finance)"""
    market_news = []
    
    # 1. Yahoo Finance (ì‹ ë¢°ì˜¤ ì†ŒìŠ¤ ìš°ì„  - SPY, QQQ, NVDA)
    market_news.extend(fetch_yahoo_news(["SPY", "QQQ", "^DJI"]))
    
    # 2. Google News (ë³´ì¡°)
    # ê´‘ë²”ìœ„í•œ ì‹œì¥ í‚¤ì›Œë“œ
    query = "stock market live updates Fed CPI inflation earnings report when:3d"
    encoded = requests.utils.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(url)
        for e in feed.entries:
            # ë‚ ì§œ íŒŒì‹±
            if hasattr(e, 'published_parsed') and e.published_parsed:
                dt = datetime(*e.published_parsed[:6])
            else:
                dt = datetime.now()

            market_news.append({
                "title": e.title,
                "link": e.link,
                "published": e.published,
                "published_dt": dt, # ì •ë ¬ìš©
                "source": e.source.title if hasattr(e, 'source') else "News"
            })
    except: pass
    
    # ì¤‘ë³µ ì œê±° (Link ê¸°ì¤€) & ì •ë ¬
    seen_links = set()
    unique_news = []
    for n in market_news:
        if n['link'] not in seen_links:
            unique_news.append(n)
            seen_links.add(n['link'])
            
    # ìµœì‹ ìˆœ ì •ë ¬
    unique_news.sort(key=lambda x: x['published_dt'], reverse=True)
    
    return unique_news[:7] # Top 7 (ì•¼í›„ ì¶”ê°€ë¡œ ê°œìˆ˜ ëŠ˜ë¦¼)

@st.cache_data(ttl=3600)
def fetch_ib_news(bank_name):
    """ì£¼ìš” IBë“¤ì˜ ìµœì‹  ë§ˆì¼“ ì½”ë©˜íŠ¸ ìˆ˜ì§‘ (Google News + Yahoo Finance)"""
    ib_news = []
    
    # 1. Yahoo Finance (í‹°ì»¤ ë§¤í•‘)
    ticker_map = {
        "JP Morgan": "JPM",
        "Goldman Sachs": "GS",
        "Morgan Stanley": "MS"
    }
    
    if bank_name in ticker_map:
        ib_news.extend(fetch_yahoo_news([ticker_map[bank_name]]))

    # 2. Google News RSS
    # ê²€ìƒ‰ì–´ ìµœì í™”: "BankName market outlook 2025" or "BankName stock strategy" relative to last 30 days
    query = f"{bank_name} market outlook strategy forecast when:30d"
    encoded = requests.utils.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(url)
        for e in feed.entries:
            # ë‚ ì§œ íŒŒì‹±
            if hasattr(e, 'published_parsed') and e.published_parsed:
                dt = datetime(*e.published_parsed[:6])
            else:
                dt = datetime.now()

            ib_news.append({
                "title": e.title,
                "link": e.link,
                "published": e.published,
                "published_dt": dt,
                "source": e.source.title if hasattr(e, 'source') else "News"
            })
    except: pass
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    seen_titles = set()
    unique_news = []
    for n in ib_news:
        # ì œëª©ì´ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ ì¤‘ë³µ ì²˜ë¦¬ (ê°„ë‹¨í•œ ë¡œì§)
        title_summary = n['title'][:30]
        if title_summary not in seen_titles:
            unique_news.append(n)
            seen_titles.add(title_summary)
            
    # ìµœì‹ ìˆœ ì •ë ¬
    unique_news.sort(key=lambda x: x['published_dt'], reverse=True)
    
    return unique_news[:5] # Top 5

def get_news_tags(title):
    """ë‰´ìŠ¤ ì œëª© ê¸°ë°˜ íƒœê·¸ ìƒì„± (NLP-lite)"""
    title_lower = title.lower()
    tags = []
    
    # 1. Momentum (Positive)
    if any(k in title_lower for k in ["upgrade", "buy", "bull", "overweight", "raise", "top pick", "growth", "positive", "hike"]):
        tags.append(("ğŸš€ Momentum", "#FFEAEA", "#FF0000")) # Text, BG, Color
        
    # 2. Risk (Negative)
    if any(k in title_lower for k in ["downgrade", "sell", "bear", "underweight", "cut", "risk", "warn", "negative", "slow", "recession"]):
        tags.append(("âš ï¸ Risk", "#EAEFFF", "#0000FF"))
        
    # 3. Key Event (Neutral/Impact)
    if any(k in title_lower for k in ["fed", "rate", "cpi", "inflation", "earnings", "policy", "meeting", "tech", "ai "]):
        tags.append(("ğŸ“¢ Event", "#F2F2F2", "#333333"))
        
    return tags

@st.cache_data(ttl=86400)
def fetch_statcounter_data(metric="search_engine", device="desktop+mobile+tablet+console", region="ww", from_year="2019", from_month="01", to_year=None, to_month=None):
    """StatCounter ë°ì´í„° ìˆ˜ì§‘ (CSV Direct)"""
    import requests
    import io
    from datetime import datetime
    
    # to_year/to_monthê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ ê¸°ì¤€
    if to_year is None or to_month is None:
        now = datetime.now()
        to_year = now.year
        to_month = now.month
    
    base_url = "https://gs.statcounter.com/chart.php"
    
    # device íŒŒë¼ë¯¸í„° ì²˜ë¦¬
    # device_hidden ê°’ ì„¤ì • (StatCounterëŠ” device_hiddenì„ ì£¼ë¡œ ì‚¬ìš©)
    device_val = device
    
    # metric ì„¤ì •
    if metric == "search_engine":
        stat_type_hidden = "search_engine"
        stat_type_label = "Search Engine"
    elif metric == "os":
        stat_type_hidden = "os_combined"
        stat_type_label = "OS Market Share"
    elif metric == "browser":
        stat_type_hidden = "browser"
        stat_type_label = "Browser"
        
    params = {
        "device": device, # Label text but utilizing same val for simplicity or need map? 
        # Actually StatCounter url uses 'device' param for label and 'device_hidden' for value.
        # But 'device' param in getting csv might be loose. Let's use correct hidden val.
        "device_hidden": device_val, 
        "multi-device": "true",
        "statType_hidden": stat_type_hidden,
        "region_hidden": region,
        "granularity": "monthly",
        "statType": stat_type_label,
        "region": "Worldwide",
        "fromInt": f"{from_year}{from_month}",
        "toInt": f"{to_year}{to_month:02d}",
        "fromMonthYear": f"{from_year}-{from_month}",
        "toMonthYear": f"{to_year}-{to_month:02d}",
        "csv": "1"
    }
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        response = requests.get(base_url, params=params, headers=headers, verify=False)
        if response.status_code == 200:
            df = pd.read_csv(io.StringIO(response.text))
            # ë‚ ì§œë¥¼ YYYY-MM í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
            df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m')
            df.set_index('Date', inplace=True)
            return df
        else:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

def process_search_engine_data(df):
    """Google, Bing, Yahoo, Other 4íŒŒì „ìœ¼ë¡œ ì •ë¦¬"""
    if df.empty:
        return df
        
    # CSV header might be 'bing' or 'Bing', 'Yahoo!' or 'Yahoo'
    cols = df.columns
    
    # Bing ì´ë¦„ í™•ì¸
    bing_col = 'bing' if 'bing' in cols else 'Bing'
    # Yahoo ì´ë¦„ í™•ì¸
    yahoo_col = 'Yahoo!' if 'Yahoo!' in cols else 'Yahoo'
    
    final_targets = ['Google', bing_col, yahoo_col]
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    valid_targets = [c for c in final_targets if c in cols]
    
    # Other ê³„ì‚°
    other_cols = [c for c in cols if c not in valid_targets]
    
    df_processed = df[valid_targets].copy()
    if other_cols:
        df_processed['Other'] = df[other_cols].sum(axis=1)
    
    # ì´ë¦„ í†µì¼
    rename_map = {}
    if yahoo_col in df_processed.columns:
        rename_map[yahoo_col] = 'Yahoo'
    if bing_col in df_processed.columns:
        rename_map[bing_col] = 'Bing'
        
    if rename_map:
        df_processed.rename(columns=rename_map, inplace=True)
        
    # ìš”ì²­ëœ ìˆœì„œë¡œ ì •ë ¬: Google, Yahoo, Other, Bing
    desired_order = ['Google', 'Yahoo', 'Other', 'Bing']
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§í•˜ì—¬ ìˆœì„œ ì ìš©
    final_order = [c for c in desired_order if c in df_processed.columns]
    
    return df_processed[final_order]

# ë°ì´í„° ë¡œë“œ
macro_metrics, macro_histories = fetch_market_data()

# ---------------------------------------------------------
# 3. ì‚¬ì´ë“œë°” êµ¬ì„±
# ---------------------------------------------------------
with st.sidebar:
    st.title("ğŸŠ Mirae Asset")
    st.subheader("ê³ ê°ìì‚°ë°°ë¶„ë³¸ë¶€")
    st.caption("Strategy Dashboard V4.1")
    st.markdown("---")
    
    menu = st.radio("ë©”ë‰´ ì„ íƒ", [
        "ğŸ“° Daily Market Narrative", 
        "ğŸ“ˆ Super-Stock",
        "ğŸ“Š TIMEFOLIO Analysis"
    ])
    
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

# ---------------------------------------------------------
# 4. ë©”ì¸ í™”ë©´ ë¡œì§
# ---------------------------------------------------------

# [TAB 1] Daily Market Narrative (ëª¨ë‹ ë¯¸íŒ…ìš©)
if menu == "ğŸ“° Daily Market Narrative":
    st.title("ğŸ“° Daily Market Narrative")
    st.markdown("### â˜• Morning Meeting Board")
    st.info("ì˜¤ëŠ˜ì˜ ì‹œì¥ í™˜ê²½ì„ ì ê²€í•˜ê³ , ìœ ë‹ˆë²„ìŠ¤ í…Œë§ˆì˜ ë¦¬ë°¸ëŸ°ì‹± ì „ëµì„ ë…¼ì˜í•˜ëŠ” ê³µê°„ì…ë‹ˆë‹¤.")

    # 1. Macro Environment (ì‹œì¥ í™˜ê²½ ì ê²€)
    st.markdown("#### 1. Macro Environment (ì‹œì¥ ë¶„ìœ„ê¸°)")
    cols = st.columns(6)
    
    # í•µì‹¬ ì§€í‘œ ë‚˜ì—´
    indicators = ["KOSPI", "S&P500", "Nasdaq", "USD/KRW", "US 10Y", "WTI Oil"]
    for i, key in enumerate(indicators):
        if key in macro_metrics:
            with cols[i]:
                d = macro_metrics[key]
                color = "normal" if d['pct_change'] >= 0 else "inverse"
                st.metric(key, f"{d['price']:,.2f}", f"{d['pct_change']:.2f}%", delta_color=color)


    st.markdown("---")

    # 1.5 Global Market Event Radar (New Feature)
    st.markdown("#### ğŸš¨ Global Market Event Radar (Key Events)")
    st.info("ğŸŒ ì´ë²ˆ ì£¼ ì‹œì¥ì„ ì›€ì§ì´ëŠ” í•µì‹¬ ë§¤í¬ë¡œ ì´ë²¤íŠ¸ & ë‰´ìŠ¤")
    
    global_events = fetch_global_events()
    if global_events:
        for n in global_events:
            # ë‚ ì§œ í¬ë§·íŒ…
            try:
                dt = datetime.strptime(n['published'], "%a, %d %b %Y %H:%M:%S %Z")
                date_str = dt.strftime("%Y-%m-%d %H:%M")
            except:
                date_str = ""
            
            # íƒœê·¸ ë¶„ì„
            tags = get_news_tags(n['title'])
            tag_html = ""
            for t_text, t_bg, t_col in tags:
                tag_html += f"<span style='background-color:{t_bg}; color:{t_col}; padding: 2px 6px; border-radius: 4px; font-size: 11px; margin-right: 4px; font-weight: bold;'>{t_text}</span>"
            
            # ì¹´ë“œ ìŠ¤íƒ€ì¼ (ì¡°ê¸ˆ ë” ê°•ì¡°ëœ ë””ìì¸)
            st.markdown(f"""
            <div style="padding: 12px; border-left: 4px solid #FF5050; background-color: #fff; box-shadow: 0 1px 3px rgba(0,0,0,0.1); margin-bottom: 10px;">
                <a href="{n['link']}" target="_blank" style="text-decoration: none; color: #111; font-weight: bold; font-size: 15px;">{n['title']}</a>
                <br><div style="margin-top: 6px;">{tag_html} <span style="color: #666; font-size: 12px;">{n['source']} | {date_str}</span></div>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.write("í˜„ì¬ ê°ì§€ëœ ì£¼ìš” ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # 2. Global IB House View (ëŒ€ì²´ëœ ê¸°ëŠ¥)
    st.markdown("#### 2. Global IB House View (Wall St. Insight)")
    st.info("ğŸ’¡ ì›”ê°€ ì£¼ìš” íˆ¬ìì€í–‰(IB)ë“¤ì˜ ìµœì‹  ì‹œì¥ ì „ë§ ë° ì „ëµ ë¦¬í¬íŠ¸ ìš”ì•½")

    ib_banks = {
        "JP Morgan": "https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/J_P_Morgan_Chase_Logo_2008_1.svg/1200px-J_P_Morgan_Chase_Logo_2008_1.svg.png",
        "Goldman Sachs": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Goldman_Sachs.svg/1200px-Goldman_Sachs.svg.png",
        "Morgan Stanley": "https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Morgan_Stanley_Logo_1.svg/1200px-Morgan_Stanley_Logo_1.svg.png"
    }
    
    cols = st.columns(3)
    for i, (bank, logo_url) in enumerate(ib_banks.items()):
        with cols[i]:
            st.markdown(f"**ğŸ¦ {bank}**")
            # st.image(logo_url, width=100) # ë¡œê³ ëŠ” ë§í¬ ê¹¨ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ìœ ì§€
            
            news = fetch_ib_news(bank)
            if news:
                for n in news:
                    # ë‚ ì§œ í¬ë§·íŒ… ê¹”ë”í•˜ê²Œ
                    try:
                        dt = datetime.strptime(n['published'], "%a, %d %b %Y %H:%M:%S %Z")
                        date_str = dt.strftime("%Y-%m-%d")
                    except:
                        date_str = ""
                    
                    # íƒœê·¸ ë¶„ì„
                    tags = get_news_tags(n['title'])
                    tag_html = ""
                    for t_text, t_bg, t_col in tags:
                        tag_html += f"<span style='background-color:{t_bg}; color:{t_col}; padding: 2px 6px; border-radius: 4px; font-size: 11px; margin-right: 4px; font-weight: bold;'>{t_text}</span>"
                        
                    st.markdown(f"""
                    <div style="padding: 10px; border: 1px solid #e0e0e0; border-radius: 5px; margin-bottom: 10px; background-color: #f9f9f9;">
                        <a href="{n['link']}" target="_blank" style="text-decoration: none; color: #333; font-weight: bold; font-size: 14px;">{n['title']}</a>
                        <br><div style="margin-top: 4px;">{tag_html} <span style="color: #666; font-size: 12px;">{n['source']} | {date_str}</span></div>
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.caption("ìµœì‹  ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # 3. Discussion & Action Plan (íšŒì˜ë¡ ì‘ì„±)
    st.markdown("#### 3. Today's Action Plan (íšŒì˜ ê¸°ë¡)")
    
    c_memo1, c_memo2 = st.columns(2)
    with c_memo1:
        st.text_area("ğŸ—£ï¸ Macro View & Issue", height=150, placeholder="ì˜ˆ: ë¯¸ êµ­ì±„ ê¸ˆë¦¬ ìƒìŠ¹ìœ¼ë¡œ ì¸í•œ ì„±ì¥ì£¼ ì¡°ì • ê°€ëŠ¥ì„± ë…¼ì˜...")
    with c_memo2:
        st.text_area("âš–ï¸ Rebalancing Idea", height=150, placeholder="ì˜ˆ: 'AI ë°˜ë„ì²´' ë¹„ì¤‘ ìœ ì§€í•˜ë˜, '2ì°¨ì „ì§€' ë¹„ì¤‘ ì¶•ì†Œ ì˜ê²¬ ìš°ì„¸...")


# [TAB 2] Super-Stock (StatCounter) - íŒ€ì¥ë‹˜ ê°œì¸ ì—…ë¬´
if menu == "ğŸ“ˆ Super-Stock":
    st.header("ğŸ“ˆ Super-Stock (Global Market Share)")
    st.caption("Data Source: StatCounter Global Stats")
    
    # ë©”ì¸ íƒ­ ë¶„ë¦¬: ê²€ìƒ‰ì—”ì§„ vs ëª¨ë°”ì¼ OS
    main_tab1, main_tab2 = st.tabs(["ğŸ” Search Engine War", "ğŸ“± OS Rivalry (Android vs iOS)"])
    
    # [Tab 1] ê²€ìƒ‰ì—”ì§„ (ê¸°ì¡´ ê¸°ëŠ¥)
    with main_tab1:
        st.subheader("Global Search Engine Market Share")
        st.caption("Google vs Bing vs Yahoo vs Other")
        
        sub_tab1, sub_tab2, sub_tab3 = st.tabs(["ğŸ–¥ï¸+ğŸ“± Desktop & Mobile", "ğŸ–¥ï¸ Desktop", "ğŸ“± Mobile"])
        
        # 1. Desktop + Mobile (Combined)
        with sub_tab1:
            df = fetch_statcounter_data("search_engine", device="desktop+mobile+tablet+console")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                # ë§‰ëŒ€ ì°¨íŠ¸ (Stacked Bar)
                fig = px.bar(df_proc, title="Search Engine M/S (Total)", barmode='stack', 
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                # Yì¶• ìŠ¤ì¼€ì¼ ì¡°ì • (ë¹„ìœ¨ íŒŒì•… ìš©ì´í•˜ë„ë¡)
                y_min = df_proc['Google'].min() - 5
                if y_min < 0: y_min = 0
                fig.update_layout(yaxis_range=[y_min, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))
                
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

        # 2. Desktop
        with sub_tab2:
            df = fetch_statcounter_data("search_engine", device="desktop")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                fig = px.bar(df_proc, title="Search Engine M/S (Desktop)", barmode='stack',
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                y_min = df_proc['Google'].min() - 5
                if y_min < 0: y_min = 0
                fig.update_layout(yaxis_range=[y_min, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))

                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

        # 3. Mobile
        with sub_tab3:
            df = fetch_statcounter_data("search_engine", device="mobile")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                fig = px.bar(df_proc, title="Search Engine M/S (Mobile)", barmode='stack',
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                y_min = df_proc['Google'].min() - 5
                if y_min < 0: y_min = 0
                fig.update_layout(yaxis_range=[y_min, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))

                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

    # [Tab 2] OS Rivalry (New Feature)
    with main_tab2:
        st.subheader("ğŸ“± Mobile & Tablet OS Rivalry (Android vs iOS)")
        st.caption("Which ecosystem is winning? (Data since 2009)")
        
        # ì»¨íŠ¸ë¡¤ íŒ¨ë„
        c1, c2 = st.columns([1, 1])
        with c1:
            os_device = st.radio("Platform", ["Mobile", "Tablet", "Mobile + Tablet"], horizontal=True)
            # íŒŒë¼ë¯¸í„° ë§¤í•‘
            device_param_map = {
                "Mobile": "mobile",
                "Tablet": "tablet",
                "Mobile + Tablet": "mobile+tablet"
            }
            target_device = device_param_map[os_device]
            
        with c2:
            # ì—°ë„ ë¦¬ìŠ¤íŠ¸ ìƒì„± (í˜„ì¬ ì—°ë„ ~ 2009)
            current_year = datetime.now().year
            year_options = [str(y) for y in range(current_year, 2008, -1)]
            period_options = ["Last 12 Months"] + year_options + ["All Time"]
            period = st.selectbox("Period", period_options)
            
        # ë°ì´í„° ìˆ˜ì§‘ (2009ë…„ë¶€í„° ìµœëŒ€ì¹˜)
        # í†µì‹  ì—ëŸ¬ ë°©ì§€ìš© ì˜ˆì™¸ì²˜ë¦¬
        try:
            df_os = fetch_statcounter_data("os", device=target_device, from_year="2009", from_month="01")
        except Exception:
            df_os = pd.DataFrame()
        
        if not df_os.empty:
            # Android, iOS, iPadOS í•„í„°ë§
            targets = ['Android', 'iOS', 'iPadOS']
            # ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸ (ëŒ€ì†Œë¬¸ì ì´ìŠˆ ë°©ì§€)
            valid_targets = []
            rename_map = {}
            for t in targets:
                # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  ì°¾ê¸°
                for col in df_os.columns:
                    if t.lower() == col.lower():
                        valid_targets.append(col)
                        rename_map[col] = t # í‘œì¤€ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
                        break
            
            if len(valid_targets) > 0:
                df_final = df_os[valid_targets].copy()
                df_final.rename(columns=rename_map, inplace=True)
                
                # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (iloc ìŠ¬ë¼ì´ì‹±ì„ ìœ„í•´ í•„ìˆ˜)
                df_final.sort_index(ascending=True, inplace=True)
                
                # ê¸°ê°„ í•„í„°ë§
                if period == "Last 12 Months":
                    df_final = df_final.iloc[-13:] # User Request: 2024-12 ~ 2025-12 (13 months)
                elif period == "All Time":
                    pass
                elif period.isdigit(): # "2025", "2024" etc.
                    df_final = df_final[df_final.index.str.startswith(period)]
                
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´
                if df_final.empty:
                    st.warning(f"ì„ íƒí•˜ì‹  ê¸°ê°„({period})ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # Tooltip ì •ë ¬ì„ ìœ„í•´ ë§ˆì§€ë§‰ ë°ì´í„° ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì»¬ëŸ¼ ì¬ì •ë ¬
                    # (User Request: ë†’ì´ ìˆëŠ” ìˆ«ìë‘ ì¢…ë¥˜ë¶€í„° ëœ¨ê²Œ)
                    last_row = df_final.iloc[-1]
                    sorted_cols = last_row.sort_values(ascending=False).index.tolist()
                    df_final = df_final[sorted_cols]
                
                # êº¾ì€ì„  ì°¨íŠ¸ (Line Chart)
                # ë°ì´í„° í¬ì¸íŠ¸ê°€ ë§ìœ¼ë©´ ë§ˆì»¤ë¥¼ ìˆ¨ê²¨ì„œ ê¹”ë”í•˜ê²Œ (20ê°œ ë¯¸ë§Œì¼ ë•Œë§Œ í‘œì‹œ)
                show_markers = True if len(df_final) < 20 else False
                
                # ìƒ‰ìƒ ì„¤ì • (User Request: StatCounter Style - Android Orange, iOS Gray)
                colors = {'Android': '#F48024', 'iOS': '#555555', 'iPadOS': '#555555'}
                
                fig = px.line(df_final, title=f"OS Market Share ({os_device}) - {period}", 
                              color_discrete_map=colors,
                              markers=show_markers) 
                
                # ë¼ì¸ ë‘ê»˜ ì„¤ì •
                fig.update_traces(line=dict(width=3))
                
                # ë¼ì¸ ë‘ê»˜ ì„¤ì •
                fig.update_traces(line=dict(width=3))
                
                # Yì¶• & Range Slider ì„¤ì •
                fig.update_layout(
                    # yaxis_range=[0, 100], # ê³ ì • ë²”ìœ„ ì œê±° (Autoë¡œ ì´ë¯¸ì§€ì²˜ëŸ¼ Zoom íš¨ê³¼)
                    yaxis=dict(rangemode='tozero'), # 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ê°•ì œ
                    xaxis=dict(
                        rangeslider=dict(visible=False), # ìš”ì²­ëŒ€ë¡œ ì œê±°
                        type="date"
                    ),
                    legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5),
                    hovermode="x", # User Request: ìˆ˜ì¹˜ë¥¼ ë”°ë¡œ í‘œì‹œ (Separate)
                    plot_bgcolor='white' # ì´ë¯¸ì§€ì²˜ëŸ¼ ë°°ê²½ ê¹”ë”í•˜ê²Œ
                )
                fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#E5E5E5')
                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#E5E5E5') # ê²©ì í‘œì‹œ
                
                st.plotly_chart(fig, use_container_width=True)
                
                # ë°ì´í„° í…Œì´ë¸”
                st.markdown("### ğŸ“Š Monthly Data")
                st.dataframe(df_final.sort_index(ascending=False).style.format("{:.1f}%"), use_container_width=True)
            else:
                st.warning("Android ë˜ëŠ” iOS ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.error("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


# [TAB 3] TIMEFOLIO Analysis (ê²½ìŸì‚¬ ë¶„ì„)
if menu == "ğŸ“Š TIMEFOLIO Analysis":
    st.title("ğŸ“Š TIMEFOLIO Official Portfolio & Rebalancing")
    
    etf_categories = {
        "í•´ì™¸ì£¼ì‹í˜• (10ì¢…)": {
            "ê¸€ë¡œë²Œíƒ‘í”½": "22", "ê¸€ë¡œë²Œë°”ì´ì˜¤": "9", "ìš°ì£¼í…Œí¬&ë°©ì‚°": "20",
            "S&P500": "5", "ë‚˜ìŠ¤ë‹¥100": "2", "ê¸€ë¡œë²ŒAI": "6",
            "ì°¨ì´ë‚˜AI": "19", "ë¯¸êµ­ë°°ë‹¹ë‹¤ìš°ì¡´ìŠ¤": "18",
            "ë¯¸êµ­ë‚˜ìŠ¤ë‹¥100ì±„ê¶Œí˜¼í•©50": "10", "ê¸€ë¡œë²Œì†Œë¹„íŠ¸ë Œë“œ": "8"
        },
        "êµ­ë‚´ì£¼ì‹í˜• (7ì¢…)": {
            "Kì‹ ì¬ìƒì—ë„ˆì§€": "16", "Kë°”ì´ì˜¤": "13", "Koreaí”ŒëŸ¬ìŠ¤ë°°ë‹¹": "12",
            "ì½”ìŠ¤í”¼": "11", "ì½”ë¦¬ì•„ë°¸ë¥˜ì—…": "15", "Kì´ë…¸ë² ì´ì…˜": "17", "Kì»¬ì²˜": "1"
        }
    }
    
    c1, c2 = st.columns(2)
    with c1:
        cat = st.selectbox("ë¶„ë¥˜", list(etf_categories.keys()))
    with c2:
        name = st.selectbox("ìƒí’ˆëª…", list(etf_categories[cat].keys()))
    
    target_idx = etf_categories[cat][name]
    
    if st.button("ë°ì´í„° ë¶„ì„ ë° ë¦¬ë°¸ëŸ°ì‹± ìš”ì•½") or st.session_state.get(f"analysis_active_{target_idx}", False):
        st.session_state[f"analysis_active_{target_idx}"] = True

        with st.spinner(f"'{name}' ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ActiveETFMonitor ì´ˆê¸°í™”
                monitor = ActiveETFMonitor(url=f"https://timefolioetf.co.kr/m11_view.php?idx={target_idx}", etf_name=name)
                
                # ê¸ˆì¼ ë‚ ì§œ (í•œêµ­ ì‹œê°„)
                today = datetime.now(pytz.timezone('Asia/Seoul')).strftime("%Y-%m-%d")
                
                # ê¸ˆì¼ ë°ì´í„° ìˆ˜ì§‘
                df_today = monitor.get_portfolio_data(today)
                monitor.save_data(df_today, today)
                
                # ì „ì¼ ë°ì´í„° ë¡œë“œ (ì—†ìœ¼ë©´ í¬ë¡¤ë§)
                try:
                    prev_day = monitor.get_previous_business_day(today)
                    df_prev = monitor.load_data(prev_day)
                    
                    # ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ ìˆ˜í–‰
                    analysis = monitor.analyze_rebalancing(df_today, df_prev, prev_day, today)
                    analysis_success = True
                except Exception as e:
                    st.warning(f"ì „ì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤: {e}")
                    analysis_success = False
                    df_prev = None

                st.success(f"âœ… {name} ë°ì´í„° ë¶„ì„ ì™„ë£Œ" + (f" (ê¸°ì¤€: {today} vs {prev_day})" if analysis_success else ""))

                # --- ë¦¬ë°¸ëŸ°ì‹± ìš”ì•½ (ë¶„ì„ ì„±ê³µ ì‹œ) ---
                if analysis_success:
                    st.subheader("ğŸ”„ ë¦¬ë°¸ëŸ°ì‹± ì •ë°€ ë¶„ì„ (ì‹œì¥ìˆ˜ìµë¥  ì¡°ì • ë°˜ì˜)")
                    
                    # ìš”ì•½ ë©”íŠ¸ë¦­
                    m1, m2, m3, m4 = st.columns(4)
                    m1.metric("ë¹„ì¤‘ í™•ëŒ€", f"{len(analysis['increased_stocks'])} ì¢…ëª©")
                    m2.metric("ë¹„ì¤‘ ì¶•ì†Œ", f"{len(analysis['decreased_stocks'])} ì¢…ëª©")
                    m3.metric("ì‹ ê·œ í¸ì…", f"{len(analysis['new_stocks'])} ì¢…ëª©")
                    m4.metric("ì™„ì „ í¸ì¶œ", f"{len(analysis['removed_stocks'])} ì¢…ëª©")

                    # íƒ­ êµ¬ì„±
                    tab1, tab2, tab3 = st.tabs(["ì£¼ìš” ë³€ê²½ë‚´ì—­", "ì„¸ë¶€ ë³€ë™", "ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤"])
                    
                    with tab1:
                        # ì‹ ê·œ í¸ì… & í¸ì¶œ
                        c1, c2 = st.columns(2)
                        with c1:
                            st.markdown("##### ğŸŸ¢ ì‹ ê·œ í¸ì…")
                            if analysis['new_stocks']:
                                rows = []
                                for s in analysis['new_stocks']:
                                    rows.append({
                                        "ì¢…ëª©ëª…": s['ì¢…ëª©ëª…'],
                                        "í˜„ì¬ë¹„ì¤‘": f"{s['ë¹„ì¤‘_today']:.2f}%",
                                        "ìˆœìˆ˜ë³€ë™": f"+{s['ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']:.2f}%p"
                                    })
                                st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)
                            else:
                                st.caption("ì‹ ê·œ í¸ì… ì¢…ëª© ì—†ìŒ")

                        with c2:
                            st.markdown("##### ğŸ”´ ì™„ì „ í¸ì¶œ")
                            if analysis['removed_stocks']:
                                rows = []
                                for s in analysis['removed_stocks']:
                                    rows.append({
                                        "ì¢…ëª©ëª…": s['ì¢…ëª©ëª…'],
                                        "ì´ì „ë¹„ì¤‘": f"{s['ë¹„ì¤‘_prev']:.2f}%",
                                        "ìˆœìˆ˜ë³€ë™": f"{s['ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']:.2f}%p"
                                    })
                                st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)
                            else:
                                st.caption("ì™„ì „ í¸ì¶œ ì¢…ëª© ì—†ìŒ")

                    with tab2:
                        # ë¹„ì¤‘ í™•ëŒ€ & ì¶•ì†Œ
                        c1, c2 = st.columns(2)
                        with c1:
                            st.markdown("##### ğŸ”¼ ë¹„ì¤‘ í™•ëŒ€ (Top 5)")
                            if analysis['increased_stocks']:
                                df_inc = pd.DataFrame(analysis['increased_stocks'])
                                df_inc = df_inc.sort_values('ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”', ascending=False).head(5)
                                display_df = df_inc[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']].copy()
                                display_df.columns = ['ì¢…ëª©ëª…', 'ì´ì „(%)', 'í˜„ì¬(%)', 'ë³€ë™(%p)']
                                st.dataframe(display_df.style.format({'ì´ì „(%)': '{:.2f}', 'í˜„ì¬(%)': '{:.2f}', 'ë³€ë™(%p)': '+{:.2f}'}), hide_index=True, use_container_width=True)
                            else:
                                st.caption("ë¹„ì¤‘ í™•ëŒ€ ì¢…ëª© ì—†ìŒ")

                        with c2:
                            st.markdown("##### ğŸ”½ ë¹„ì¤‘ ì¶•ì†Œ (Top 5)")
                            if analysis['decreased_stocks']:
                                df_dec = pd.DataFrame(analysis['decreased_stocks'])
                                df_dec = df_dec.sort_values('ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”', ascending=True).head(5)
                                display_df = df_dec[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']].copy()
                                display_df.columns = ['ì¢…ëª©ëª…', 'ì´ì „(%)', 'í˜„ì¬(%)', 'ë³€ë™(%p)']
                                st.dataframe(display_df.style.format({'ì´ì „(%)': '{:.2f}', 'í˜„ì¬(%)': '{:.2f}', 'ë³€ë™(%p)': '{:.2f}'}), hide_index=True, use_container_width=True)
                            else:
                                st.caption("ë¹„ì¤‘ ì¶•ì†Œ ì¢…ëª© ì—†ìŒ")
                                
                        st.info("* **ìˆœìˆ˜ ë³€ë™**: ì‹œì¥ ê°€ê²© ë“±ë½ì— ì˜í•œ 'ê°€ìƒ ë¹„ì¤‘'ì„ ì œì™¸í•œ ë§¤ë‹ˆì €ì˜ ì‹¤ì œ ë§¤ë§¤ë¡œ ì¸í•œ ë¹„ì¤‘ ë³€í™” (ì¶”ì •ì¹˜)")

                    with tab3:
                        st.markdown("##### ğŸ“‹ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±")
                # ì „ì²´ ë¦¬ìŠ¤íŠ¸ ë° ì°¨íŠ¸
                st.subheader("ğŸ“‹ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±")
                
                c_chart, c_list = st.columns([1, 1])
                
                with c_chart:
                    # ë„ë„› ì°¨íŠ¸ ë³µì›
                    chart_df = df_today.copy()
                    chart_df['ë¹„ì¤‘'] = pd.to_numeric(chart_df['ë¹„ì¤‘'], errors='coerce')
                    
                    # Top 5 ì™¸ì—ëŠ” 'ê¸°íƒ€'ë¡œ ë¬¶ê¸°
                    chart_df = chart_df.sort_values('ë¹„ì¤‘', ascending=False)
                    if len(chart_df) > 5:
                        top5 = chart_df.iloc[:5]
                        others = chart_df.iloc[5:]
                        others_sum = others['ë¹„ì¤‘'].sum()
                        others_row = pd.DataFrame([{'ì¢…ëª©ëª…': 'ê¸°íƒ€', 'ë¹„ì¤‘': others_sum}])
                        final_chart_df = pd.concat([top5, others_row], ignore_index=True)
                    else:
                        final_chart_df = chart_df

                    fig = px.pie(final_chart_df, values="ë¹„ì¤‘", names="ì¢…ëª©ëª…", hole=0.4, title="í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘", color_discrete_sequence=px.colors.qualitative.Set3)
                    fig.update_traces(textinfo='percent+label')
                    st.plotly_chart(fig, use_container_width=True)
                
                with c_list:
                    # ì „ì²´ ë°ì´í„° í‘œì‹œ (ì‹¬í”Œ í…Œì´ë¸”)
                    df_all = df_today[['ì¢…ëª©ëª…', 'ë¹„ì¤‘']].copy()
                    df_all['ë¹„ì¤‘'] = pd.to_numeric(df_all['ë¹„ì¤‘'], errors='coerce')
                    df_all = df_all.sort_values('ë¹„ì¤‘', ascending=False)
                    
                    # ì¸ë±ìŠ¤ 1ë¶€í„° ì‹œì‘ (ìˆœìœ„)
                    df_all.index = range(1, len(df_all) + 1)
                    
                    # ë¹„ì¤‘ í¬ë§·íŒ…í•˜ì—¬ í‘œì‹œ
                    st.dataframe(df_all.style.format({'ë¹„ì¤‘': '{:.2f}%'}), use_container_width=True)


                # --- [ì‹ ê·œ ê¸°ëŠ¥ 2] ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ---
                st.markdown("---")
                st.subheader("ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
                
                # ì—‘ì…€ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° í”„ë ˆì„ ì¤€ë¹„
                e_new = pd.DataFrame(analysis['new_stocks']) if analysis['new_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                e_inc = pd.DataFrame(analysis['increased_stocks']) if analysis['increased_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                e_dec = pd.DataFrame(analysis['decreased_stocks']) if analysis['decreased_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                
                excel_data = to_excel(e_new, e_inc, e_dec, df_today, today)
                
                st.download_button(
                    label="ğŸ“Š ì—‘ì…€ ë¦¬í¬íŠ¸ ë‚´ë ¤ë°›ê¸° (.xlsx)",
                    data=excel_data,
                    file_name=f"{name}_Report_{today}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

                # --- [ì‹ ê·œ ê¸°ëŠ¥ 1] ì¢…ëª© ë¹„ì¤‘ íˆìŠ¤í† ë¦¬ ---
                st.markdown("---")
                st.subheader("ğŸ“… ì¢…ëª© ë¹„ì¤‘ íˆìŠ¤í† ë¦¬ (ìµœê·¼ 30ì¼)")
                
                with st.expander("ğŸ“ˆ ê°œë³„ ì¢…ëª© íŠ¸ë Œë“œ ë¶„ì„ í¼ì¹˜ê¸°", expanded=False):
                    history_df = monitor.load_history(days=30)
                    
                    if not history_df.empty:
                        # ì¢…ëª© ì„ íƒ (Session State í™œìš©í•˜ì—¬ ì„ íƒ ìœ ì§€)
                        all_stocks = sorted(history_df['ì¢…ëª©ëª…'].unique())
                        
                        # Session state í‚¤ ìƒì„±
                        sel_key = "history_selected_stock"
                        if sel_key not in st.session_state:
                            st.session_state[sel_key] = all_stocks[0]
                            
                        # Selectbox with key
                        selected_stock = st.selectbox("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”", all_stocks, key=sel_key)
                        
                        # ì„ íƒ ì¢…ëª© ë°ì´í„° í•„í„°ë§
                        stock_history = history_df[history_df['ì¢…ëª©ëª…'] == selected_stock].sort_values('ë‚ ì§œ')
                        
                        chart = px.line(stock_history, x='ë‚ ì§œ', y='ë¹„ì¤‘', title=f"{selected_stock} ë¹„ì¤‘ ë³€í™” ì¶”ì´",
                                       markers=True, text='ë¹„ì¤‘')
                        chart.update_traces(textposition="top center")
                        st.plotly_chart(chart, use_container_width=True)
                    else:
                        st.info("ëˆ„ì ëœ íˆìŠ¤í† ë¦¬ ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ë§¤ì¼ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ë©´ ì°¨íŠ¸ê°€ í™œì„±í™”ë©ë‹ˆë‹¤.")
                

            except Exception as e:
                st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)

    st.markdown("---")
    st.link_button("ğŸŒ ê³µì‹ ìƒì„¸í˜ì´ì§€ ë°”ë¡œê°€ê¸°", f"https://timefolioetf.co.kr/m11_view.php?idx={target_idx}")
